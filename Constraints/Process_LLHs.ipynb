{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8a7968",
   "metadata": {},
   "source": [
    "This notebook processes the PPC output to get the widths on Forier Parameters: <br>\n",
    "1) parses the PPC output to get the LLHs for all Doms and shifts <br>\n",
    "2) generate the file for total LLH for each perturbed ice model and get the width for each Fourier Parameter. <br>\n",
    "3) plot the total LLH vs shift for each Fourier mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c81e7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pylab\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import brentq\n",
    "import subprocess\n",
    "\n",
    "from numpy.polynomial import polynomial\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97459e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bc7729d",
   "metadata": {},
   "source": [
    "# Parsing the ppc output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Processoutput(rootdir, outpath):\n",
    "    count=0\n",
    "    PrintEvery=100\n",
    "    fit_dirs = []\n",
    "    fit_files = glob.glob(rootdir + \"/out*\")\n",
    "    if not fit_files :\n",
    "        print(\"WARNING: No Fit Directories Found In \" + str(rootdir) )\n",
    "        return\n",
    "    else:\n",
    "        print(\"Found \"  + str(len(fit_files)) + \" Fit Files....\")\n",
    "\n",
    "\n",
    "    outfile = open(outpath, \"a\")\n",
    "\n",
    "    print(\"Writing Output to: \"  + str(outfile))\n",
    "    outfile.write(\"#Param-mode shift DOM LLH \\n\")\n",
    "\n",
    "    for fit_filen in fit_files:\n",
    "        try:\n",
    "            fit_file = open(str(fit_filen),'r')\n",
    "        except:\n",
    "            print(\"WARNING: \" + str(fit_filen) + \" Does Not Exist!\" )\n",
    "        else:\n",
    "            try:\n",
    "                lines= fit_file.readlines()     \n",
    "            except:\n",
    "                print(\"WARNING: \" + str(fit_filen) + \" Is Empty!\" )\n",
    "                break\n",
    "            HeaderLine=lines[2]\n",
    "            Param=HeaderLine.split(\"_\")[0].split(\" \")[1]\n",
    "            ParamNum=HeaderLine.split(\"_\")[1]\n",
    "            try:\n",
    "                shift=float(HeaderLine.split(\"_\")[2].replace(\".dat\",\"\"))\n",
    "                #print(\"sh\",shift)\n",
    "            except:\n",
    "                print(\"Shift not found\")\n",
    "            for line in lines[3:-1]:\n",
    "                if \"DOM \" in line:\n",
    "                    if not \"Bad\" in line:\n",
    "                        DOM=int(line.split()[1])\n",
    "                        \n",
    "                if 'LLH' in line:\n",
    "                    LLH=re.findall(\"LLH=\\d+\\.\\d+\", line)[0][4:]\n",
    "                    DT=line.split(\"=\")[2][0:-3]\n",
    "                    if(DOM!=0):\n",
    "                        writeline=str(Param)+\"-\"+str(ParamNum)+\" \" +str(shift)+ \" \" + str(DOM) + \" \" + str(LLH) \n",
    "                        outfile.write(writeline + \"\\n\")                    \n",
    "                    count=count+1\n",
    "                    #if(count%PrintEvery==0):\n",
    "                        #print(\"Absorbed \"+str(count) + \" LLHs \\n\")\n",
    "        fit_file.close()\n",
    "    outfile.close()\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amp-0:\n",
    "Processoutput(\"/data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2/Amp/0/out/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/Amp_0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phs-6:\n",
    "Processoutput(\"/data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2/Phs/6/out/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/Phs_6.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3649aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params=[\"Amp\",\"Phs\"]     #Forier Parameter (eg. Amp or Phs)\n",
    "modes=[1,2,3,4,5]       # mode (eg. 0,1,2,3...) no mode '0' for Phs\n",
    "for Param in Params:\n",
    "    for Param_num in modes:\n",
    "        outdir='/data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2/'+str(Param)+\"/\"+str(Param_num)+\"/out/\"\n",
    "        outfile='/data/user/anegi/ppc/LLHs/spice_ftp-v2/'+str(Param)+\"_\"+str(Param_num)+\".txt\"\n",
    "        Processoutput(outdir,outfile)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f965d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e585716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e5a5bc4",
   "metadata": {},
   "source": [
    "# Getting widths from the output LLHs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996aa8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLHWidths(infile,outdir_llh,outdir_widths,Bad_Doms=[]):\n",
    "    dat=np.loadtxt(infile,dtype=str)\n",
    "    params=np.unique(dat[:,0])\n",
    "    for param in params:\n",
    "        LLHDict=dict()\n",
    "        LLHDict[str(param)]=dict()\n",
    "        mask1=(dat[:,0]==str(param))\n",
    "        dat2=dat[mask1,1:]        \n",
    "        shifts=np.unique(dat2[:,0])\n",
    "      #  print(len(shifts))\n",
    "        pairs=[0,0]\n",
    "        for shift in shifts:\n",
    "            mask=(dat[:,1]==shift)\n",
    "            subdat=dat[mask,1:]         #subarray for a particular shift value\n",
    "            #print(np.shape(subdat))\n",
    "            #print(subdat)\n",
    "            LLH_shift=0\n",
    "            BadDom=[]        \n",
    "            for i in range(1,61):\n",
    "                if i not in Bad_Doms:\n",
    "                    try:\n",
    "                        LLH_dom=float(subdat[subdat[:,0]==str(i),1])      #DoM=i  ,LLH(i)=LLH_dom\n",
    "                        LLH_shift+=LLH_dom\n",
    "                        #print(LLH_dom,i)\n",
    "                    except:\n",
    "                        #print(\"shift \",shift,\"missing LLH: DoM\",i)\n",
    "                        BadDom.append(i)\n",
    "                        pass        \n",
    "            if len(BadDom)<2:\n",
    "                LLH_shift=LLH_shift*(60-len(Bad_Doms))/(60-len(Bad_Doms)-len(BadDom))                   #rescaling total LLH if only missing 1 DoM\n",
    "                LLHDict[str(param)][float(shift)]=float(LLH_shift)\n",
    "            else:                                #ignoring the shift if missing LLh for more than 1 DoM (rerun jobs for missing DoMs if required)\n",
    "                print(\"shift \",shift,\"missing LLH: DoM\",BadDom)           \n",
    "#        print(LLHDict)\n",
    "        width=[]\n",
    "        for Param in LLHDict.keys():\n",
    "            Shifts_dict=LLHDict[Param]\n",
    "            shift_llh=np.array(list(Shifts_dict.items()))\n",
    "            print(\"\\n\")\n",
    "            #print(shift_llh)\n",
    "            if os.path.isfile(str(outdir_llh)+\"/\"+str(Param.split(\"-\")[0])+\"_\"+str(Param.split(\"-\")[1])+\"_llh.txt\")==0:\n",
    "                print(\"creating new llh file for \",Param)\n",
    "                np.savetxt(str(outdir_llh)+\"/\"+str(Param.split(\"-\")[0])+\"_\"+str(Param.split(\"-\")[1])+\"_llh.txt\",shift_llh,delimiter=\" \")\n",
    "            else:\n",
    "                print(\"llh file already exists\")\n",
    "            shifts=shift_llh[:,0]\n",
    "            llhs=shift_llh[:,1]\n",
    "            llh_min=min(llhs)\n",
    "            #print(llh_min)\n",
    "            delta_llhs=llhs-llh_min\n",
    "            #print(delta_llhs)\n",
    "            X=[]\n",
    "            Y=[]\n",
    "            for i in range(0,len(shifts)):\n",
    "                if delta_llhs[i]<5:                      #only taking shifts withh LLH<5 for the curve fitting \n",
    "                    Y.append(delta_llhs[i])\n",
    "                    X.append(shifts[i])\n",
    "            FittedCurve=polynomial.polyfit(X,Y,2)        #fitting to a quadratic polynomial\n",
    "            vals=np.arange(-3,3,0.001)\n",
    "            minval=np.min(polynomial.polyval(vals,FittedCurve))\n",
    "            PlusOneSig=(-FittedCurve[1]+np.sqrt(FittedCurve[1]**2-4.*(-0.5-minval+FittedCurve[0])*FittedCurve[2]))/(2.*FittedCurve[2])\n",
    "            MinusOneSig=(-FittedCurve[1]-np.sqrt(FittedCurve[1]**2-4.*(-0.5-minval+FittedCurve[0])*FittedCurve[2]))/(2.*FittedCurve[2])\n",
    "            Zero=(PlusOneSig+MinusOneSig)/2.\n",
    "                   \n",
    "            if os.path.isfile(str(outdir_widths)+\"/\"+str(Param.split(\"-\")[0])+\"_widths.txt\")==1:\n",
    "                outfile = open(str(outdir_widths)+\"/\"+str(Param.split(\"-\")[0])+\"_widths.txt\", \"r\")\n",
    "                lines= outfile.readlines()\n",
    "                count=0\n",
    "                for line in lines:\n",
    "                    if line[0:3]==str(Param.split(\"-\")[0]) and line[4:5]==str(Param.split(\"-\")[1]):  \n",
    "                        count+=1\n",
    "                outfile.close()        \n",
    "                if count!=0:\n",
    "                    print(\"Parameter width already exists: \", Param)\n",
    "                else:\n",
    "                    print(\"writing Param width: \",Param)\n",
    "                    outfile = open(str(outdir_widths)+\"/\"+str(Param.split(\"-\")[0])+\"_widths.txt\", \"a\")\n",
    "                    writeline=str(Param.split(\"-\")[0])+\" \"+str(Param.split(\"-\")[1])+\" \"+str(Zero)+\" \"+str(MinusOneSig)+\" \"+str(PlusOneSig)                \n",
    "                    outfile.write(writeline + \"\\n\")\n",
    "                    outfile.close()\n",
    "            else: \n",
    "                print(\"creating new width file: \", str(outdir_widths)+\"/\"+str(Param.split(\"-\")[0])+\"_widths.txt\")\n",
    "                outfile = open(str(outdir_widths)+\"/\"+str(Param.split(\"-\")[0])+\"_widths.txt\", \"w\")\n",
    "                writeline=str(Param.split(\"-\")[0])+\" \"+str(Param.split(\"-\")[1])+\" \"+str(Zero)+\" \"+str(MinusOneSig)+\" \"+str(PlusOneSig)                \n",
    "                outfile.write(writeline + \"\\n\")\n",
    "                outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amp_0\n",
    "\n",
    "LLHWidths(\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/Amp_0.txt\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/\",Bad_Doms=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir=\"/data/user/anegi/ppc/LLHs/spice_ftp-v2\"\n",
    "Params=[\"Amp\",\"Phs\"]     #Forier Parameter (eg. Amp or Phs)\n",
    "modes=[1,2,4,5]       # mode (eg. 0,1,2,3...) no mode '0' for Phs\n",
    "for Param in Params:\n",
    "    for Param_num in modes:\n",
    "        infile=str(outdir)+\"_run_2/\"+str(Param)+\"_\"+str(Param_num)+\".txt\"\n",
    "        LLHWidths(infile,outdir,outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phs_6\n",
    "\n",
    "LLHWidths(\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/Phs_6.txt\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/\",Bad_Doms=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21ed15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c82ab87d",
   "metadata": {},
   "source": [
    "# Ploting the LLH vs Shift for the given Fourier Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "Param=\"Amp\"\n",
    "mode=1\n",
    "llh_dir=\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/\"\n",
    "if os.path.exists((str(llh_dir)+\"/\"+str(Param)+\"_\"+str(mode)+\"_llh.txt\"))==True:\n",
    "    data=np.loadtxt(str(llh_dir)+\"/\"+str(Param)+\"_\"+str(mode)+\"_llh.txt\")\n",
    "    shift=data[:,0]\n",
    "    llhs=data[:,1]\n",
    "    delta_llh=llhs-min(llhs)\n",
    "    shifts=[]\n",
    "    delta_llhs=[]\n",
    "    for i in range(0,len(shift)):\n",
    "        #print(delta_llh[i,1])\n",
    "        if delta_llh[i]<5:\n",
    "            delta_llhs.append(data[i,1])\n",
    "            shifts.append(data[i,0])\n",
    "        #if len(shifts.append)<5:\n",
    "            \n",
    "            \n",
    "    print(shifts)        \n",
    "    vals=np.arange(-.3,.3,0.001)\n",
    "    FittedCurve=polynomial.polyfit(shifts,delta_llhs,2)        #fitting to a quadratic polynomial\n",
    "    minval=np.min(polynomial.polyval(vals,FittedCurve))  \n",
    "    PlusOneSig=(-FittedCurve[1]+np.sqrt(FittedCurve[1]**2-4.*(-0.5-minval+FittedCurve[0])*FittedCurve[2]))/(2.*FittedCurve[2])\n",
    "    MinusOneSig=(-FittedCurve[1]-np.sqrt(FittedCurve[1]**2-4.*(-0.5-minval+FittedCurve[0])*FittedCurve[2]))/(2.*FittedCurve[2])\n",
    "    Zero=(PlusOneSig+MinusOneSig)/2.\n",
    "    print(\"2*Width= \"PlusOneSig-MinusOneSig)\n",
    "\n",
    "    pylab.figure(figsize=(3,3))\n",
    "    fitcurve=polynomial.polyval(vals,FittedCurve)\n",
    "    pylab.plot(vals,fitcurve-min(fitcurve),color='DarkRed',linewidth=2)\n",
    "    pylab.plot(shifts,delta_llhs-min(fitcurve),'o',color='red')\n",
    "    pylab.hlines(y=0.5,xmin= MinusOneSig,xmax=PlusOneSig,linestyle='solid', color='blue')\n",
    "    pylab.xlabel(\"Shift\")\n",
    "    pylab.ylabel(\"DLLH\")\n",
    "    pylab.title(str(Param)+\"_\"+str(mode))\n",
    "    pylab.ylim(0,5)\n",
    "    #pylab.ylim(0,LLHCap)\n",
    "    pylab.tight_layout()\n",
    "    pylab.xlim(-.2,.2)\n",
    "    pylab.grid()\n",
    "else:\n",
    "    print(\"file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261d3414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cf0b26e",
   "metadata": {},
   "source": [
    "## PPC Run-2 (with a finer scan over modes 1,2,4)\n",
    "delete previously created files for these modes (only run/ rerun previous code for mode 0,3,5)\n",
    "For mode 1,2,4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b78a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing output from run 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b77fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params=[\"Amp\",\"Phs\"]     #Forier Parameter (eg. Amp or Phs)\n",
    "modes=[1,2,4,]       # mode (eg. 0,1,2,3...) no mode '0' for Phs\n",
    "for Param in Params:\n",
    "    for Param_num in modes:\n",
    "        outdir='/data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2_run_2/'+str(Param)+\"/\"+str(Param_num)+\"/out/\"\n",
    "        outfile='/data/user/anegi/ppc/LLHs/spice_ftp-v2_run_2/'+str(Param)+\"_\"+str(Param_num)+\".txt\"\n",
    "        Processoutput(outdir,outfile)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70fdb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting widths from run 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b41e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01f4a2ba",
   "metadata": {},
   "source": [
    "## Correlated Params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebae919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Processoutput(rootdir, outpath):\n",
    "    count=0\n",
    "    PrintEvery=100\n",
    "    fit_dirs = []\n",
    "    fit_files = glob.glob(rootdir + \"/out*\")\n",
    "    #n=1\n",
    "\n",
    "    if not fit_files :\n",
    "        print(\"WARNING: No Fit Directories Found In \" + str(rootdir) )\n",
    "        return\n",
    "    else:\n",
    "        print(\"Found \"  + str(len(fit_files)) + \" Fit Files....\")\n",
    "\n",
    "\n",
    "    outfile = open(outpath, \"a\")\n",
    "\n",
    "    print(\"Writing Output to: \"  + str(outfile))\n",
    "    outfile.write(\"#Params_mode1_mode2  shift DOM LLH \\n\")\n",
    "\n",
    "    for fit_filen in fit_files:\n",
    "        try:\n",
    "            fit_file = open(str(fit_filen),'r')\n",
    "        except:\n",
    "            print(\"WARNING: \" + str(fit_filen) + \" Does Not Exist!\" )\n",
    "        else:\n",
    "            try:\n",
    "                lines= fit_file.readlines()     \n",
    "            except:\n",
    "                print(\"WARNING: \" + str(fit_filen) + \" Is Empty!\" )\n",
    "                break\n",
    "            HeaderLine=lines[2]\n",
    "            #print(HeaderLine)\n",
    "            Param=HeaderLine.split(\"_\")[0].split(\" \")[1]\n",
    "            ParamNum1=HeaderLine.split(\"_\")[1]\n",
    "            ParamNum2=HeaderLine.split(\"_\")[2]\n",
    "            try:\n",
    "                shift=float(HeaderLine.split(\"_\")[3].replace(\".dat\",\"\"))\n",
    "                #print(\"sh\",shift)\n",
    "            except:\n",
    "                print(\"Shift not found\")\n",
    "            for line in lines[3:-1]:\n",
    "                if \"DOM \" in line:\n",
    "                    if not \"Bad\" in line:\n",
    "                        DOM=int(line.split()[1])\n",
    "                        \n",
    "                if 'LLH' in line:\n",
    "                    try:\n",
    "                    #print(LLH,shift,DOM,fit_filen)\n",
    "                        LLH=re.findall(\"LLH=\\d+\\.\\d+\", line)[0][4:]\n",
    "                    except:\n",
    "                        LLH=re.findall(\"LLH=\\d\", line)[0][4:]\n",
    "                        print(LLH,shift,DOM,fit_filen)\n",
    "                        #LLH=re.findall(\"LLH=\\d\", line)[0][4:]\n",
    "                        #print(LLH)\n",
    "                    \n",
    "                    #DT=line.split(\"=\")[2][0:-3]\n",
    "                    if(DOM!=0):\n",
    "                        writeline=str(Param)+\"_\"+str(ParamNum1)+\"_\"+str(ParamNum2)+\" \" +str(shift)+ \" \" + str(DOM) + \" \" + str(LLH) \n",
    "                        outfile.write(writeline + \"\\n\")                    \n",
    "                    count=count+1\n",
    "                    #if(count%PrintEvery==0):\n",
    "                        #print(\"Absorbed \"+str(count) + \" LLHs \\n\")\n",
    "        fit_file.close()\n",
    "        #if n==1:\n",
    "           # break\n",
    "    outfile.close()\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AmpPhs:\n",
    "Processoutput(\"/data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2/AmpPhs/out/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/AmpPhs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9b573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec6f5648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 Fit Files....\n",
      "Writing Output to: <_io.TextIOWrapper name='/data/user/anegi/ppc/LLHs/spice_ftp-v2/AmpPhs.txt' mode='a' encoding='UTF-8'>\n",
      "1 0.3333 47 /data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2/AmpPhs/out/out_125\n",
      "1 3.0 58 /data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2/AmpPhs/out/out_749\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#AmpPhs:\n",
    "Processoutput(\"/data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2/AmpPhs/out/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/AmpPhs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a22138a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 Fit Files....\n",
      "Writing Output to: <_io.TextIOWrapper name='/data/user/anegi/ppc/LLHs/spice_ftp-v2/AmpAmp.txt' mode='a' encoding='UTF-8'>\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#AmpAmp:\n",
    "Processoutput(\"/data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2/AmpAmp/out/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/AmpAmp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34513786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 Fit Files....\n",
      "Writing Output to: <_io.TextIOWrapper name='/data/user/anegi/ppc/LLHs/spice_ftp-v2/PhsPhs.txt' mode='a' encoding='UTF-8'>\n",
      "1 0.3333 35 /data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2/PhsPhs/out/out_184\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#PhsPhs:\n",
    "Processoutput(\"/data/user/anegi/ppc/condor/ppc_logs/spice_ftp-v2/PhsPhs/out/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/PhsPhs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d33743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468b4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743eeb42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a8dc8c-32b7-473b-bc54-4a81f5ef522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated to remove outliers:\n",
    "\n",
    "def LLHWidths(infile,outdir_llh,outdir_widths,Bad_Doms=[]):\n",
    "    dat=np.loadtxt(infile,dtype=str)\n",
    "    params=np.unique(dat[:,0])\n",
    "    #print(params)\n",
    "    #params=['AmpPhs_0_5']\n",
    "    for param in params:\n",
    "        \n",
    "        LLHDict=dict()\n",
    "        LLHDict[str(param)]=dict()\n",
    "        mask1=(dat[:,0]==str(param))\n",
    "        dat2=dat[mask1,1:]        \n",
    "        shifts=np.unique(dat2[:,0])\n",
    "        #print(len(shifts))\n",
    "        #pairs=[0,0]\n",
    "        for shift in shifts:\n",
    "            mask=(dat2[:,0]==shift)\n",
    "            subdat=dat2[mask,1:]         #subarray for a particular shift value\n",
    "            LLH_shift=0\n",
    "            BadDom=[]        \n",
    "            for i in range(1,61):\n",
    "                if i not in Bad_Doms:\n",
    "                    try:\n",
    "                        LLH_dom=float(subdat[subdat[:,0]==str(i),1])      #DoM=i  ,LLH(i)=LLH_dom\n",
    "                        #print(\"dom\",LLH_dom,i)\n",
    "                        LLH_shift+=LLH_dom\n",
    "                        #print(\"total\",LLH_shift)\n",
    "                    except:\n",
    "                        #print(\"shift \",shift,\"missing LLH: DoM\",i)\n",
    "                        BadDom.append(i)\n",
    "                        pass        \n",
    "            if len(BadDom)<2:\n",
    "                LLH_shift=LLH_shift*(60-len(Bad_Doms))/(60-len(Bad_Doms)-len(BadDom))                   #rescaling total LLH if only missing 1 DoM\n",
    "                LLHDict[str(param)][float(shift)]=float(LLH_shift)\n",
    "            else:                                #ignoring the shift if missing LLh for more than 1 DoM (rerun jobs for missing DoMs if required)\n",
    "                print(\"shift \",shift,\"missing LLH: DoM\",BadDom)           \n",
    "#        print(LLHDict)\n",
    "        width=[]\n",
    "        for Param in LLHDict.keys():\n",
    "            Shifts_dict=LLHDict[Param]\n",
    "            shift_llh=np.array(list(Shifts_dict.items()))\n",
    "            #print(shift_llh)\n",
    "            if os.path.isfile(str(outdir_llh)+\"/\"+str(Param.split(\"_\")[0])+\"/\"+str(Param.split(\"_\")[0])+\"_\"+str(Param.split(\"_\")[1])+\"_\"+str(Param.split(\"_\")[2])+\"_llh.txt\")==0:\n",
    "                print(\"creating new llh file for \",Param)\n",
    "                np.savetxt(str(outdir_llh)+\"/\"+str(Param.split(\"_\")[0])+\"/\"+str(Param.split(\"_\")[0])+\"_\"+str(Param.split(\"_\")[1])+\"_\"+str(Param.split(\"_\")[2])+\"_llh.txt\",shift_llh,delimiter=\" \")\n",
    "            else:\n",
    "                print(\"llh file already exists\")\n",
    "\n",
    "            pairs_0=[]                \n",
    "            for i in shift_llh:\n",
    "                pairs_0.append([i[0],i[1]])\n",
    "        \n",
    "            \n",
    "            #This is looped to get rid of any shift having having way too low llh value:(maximum one outlier)\n",
    "            n=0\n",
    "            for n in range(0,3):\n",
    "                pairs=[]\n",
    "                llh_min=min(np.array(pairs_0)[:,1])\n",
    "                #print(\"min_llh:\",llh_min,\",  iteration:\",n)\n",
    "                for i in range(0,len(pairs_0)):\n",
    "                    #print(np.array(pairs_0)[i,1],\"cfgvh\")\n",
    "                    if np.array(pairs_0)[i,1]<llh_min+5:                      #only taking shifts withh LLH<5 for the curve fitting                   \n",
    "                        pairs.append([pairs_0[i][0],pairs_0[i][1]-llh_min])\n",
    "                #print(\"pairs\",pairs,\"iteration\",n)                \n",
    "                if len(pairs)>=5:                                        \n",
    "                    break\n",
    "                else:                                                        #if no points found close to llh min remove shift for llh min (might be wrong value)\n",
    "                    for i in range(0,len(pairs_0)):\n",
    "                        if (pairs_0[i][1])==float(llh_min):\n",
    "                            llh_err=pairs_0[i]\n",
    "                    pairs_0.remove(llh_err)\n",
    "                    n+=1  \n",
    "                    print(\"Warning: removing min llh shift\",Param)\n",
    "            if n==3:                                                      \n",
    "                print(\"no llhs found below threshold\",Param)\n",
    "                continue\n",
    "                \n",
    "                 \n",
    "            FittedCurve=polynomial.polyfit(np.array(pairs)[:,0],np.array(pairs)[:,1],2)        #fitting to a quadratic polynomial\n",
    "            vals=np.arange(-3,3,0.001)\n",
    "            minval=np.min(polynomial.polyval(vals,FittedCurve))\n",
    "            PlusOneSig=(-FittedCurve[1]+np.sqrt(FittedCurve[1]**2-4.*(-0.5-minval+FittedCurve[0])*FittedCurve[2]))/(2.*FittedCurve[2])\n",
    "            MinusOneSig=(-FittedCurve[1]-np.sqrt(FittedCurve[1]**2-4.*(-0.5-minval+FittedCurve[0])*FittedCurve[2]))/(2.*FittedCurve[2])\n",
    "            Zero=(PlusOneSig+MinusOneSig)/2.\n",
    "            if str(Param.split(\"_\")[1])==str(0):\n",
    "                print(PlusOneSig)\n",
    "            if os.path.isfile(str(outdir_widths)+\"/\"+str(Param.split(\"_\")[0])+\"_widths.txt\")==1:\n",
    "                outfile = open(str(outdir_widths)+\"/\"+str(Param.split(\"_\")[0])+\"_widths.txt\", \"r\")\n",
    "                lines= outfile.readlines()\n",
    "                count=0\n",
    "                for line in lines:\n",
    "                   # print(line[0],line[2])\n",
    "                    if line[0]==str(Param.split(\"_\")[1]) and line[2]==str(Param.split(\"_\")[2]):  \n",
    "                        count+=1\n",
    "                outfile.close()        \n",
    "                if count!=0:\n",
    "                    print(\"Parameter width already exists: \", Param)\n",
    "                else:\n",
    "                    print(\"writing Param width: \",Param)\n",
    "                    outfile = open(str(outdir_widths)+\"/\"+str(Param.split(\"_\")[0])+\"_widths.txt\", \"a\")\n",
    "                    writeline=str(Param.split(\"_\")[1])+\" \"+str(Param.split(\"_\")[2])+\" \"+str(Zero)+\" \"+str(MinusOneSig)+\" \"+str(PlusOneSig)                \n",
    "                    outfile.write(writeline + \"\\n\")\n",
    "                    outfile.close()\n",
    "            else: \n",
    "                print(\"creating new width file: \", str(outdir_widths)+\"/\"+str(Param.split(\"_\")[0])+\"_widths.txt\")\n",
    "                outfile = open(str(outdir_widths)+\"/\"+str(Param.split(\"_\")[0])+\"_widths.txt\", \"w\")\n",
    "                writeline=\"# Param1 Param2 central -1sig +1sig\"                \n",
    "                outfile.write(writeline + \"\\n\")\n",
    "                writeline=str(Param.split(\"_\")[1])+\" \"+str(Param.split(\"_\")[2])+\" \"+str(Zero)+\" \"+str(MinusOneSig)+\" \"+str(PlusOneSig)                \n",
    "                outfile.write(writeline + \"\\n\")\n",
    "                outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7c5d67f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "llh file already exists\n",
      "-0.15490760508542467\n",
      "creating new width file:  /data/user/anegi/ppc/LLHs/spice_ftp-v2/widths//AmpPhs_widths.txt\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "0.6876543907948705\n",
      "writing Param width:  AmpPhs_0_2\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "1.4719006982076583\n",
      "writing Param width:  AmpPhs_0_3\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "1.2840618504941188\n",
      "writing Param width:  AmpPhs_0_4\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "Warning: removing min llh shift AmpPhs_0_5\n",
      "0.8019939359579952\n",
      "writing Param width:  AmpPhs_0_5\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_1_1\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_1_2\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_1_3\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_1_4\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_1_5\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_2_1\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_2_2\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_2_3\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_2_4\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_2_5\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_3_1\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_3_2\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_3_3\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_3_4\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_3_5\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_4_1\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_4_2\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_4_3\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "writing Param width:  AmpPhs_4_4\n",
      "\n",
      "\n",
      "llh file already exists\n",
      "Warning: removing min llh shift AmpPhs_4_5\n",
      "writing Param width:  AmpPhs_4_5\n"
     ]
    }
   ],
   "source": [
    "#AmpPhs\n",
    "\n",
    "LLHWidths(\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/AmpPhs.txt\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/llhs/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/widths/\",Bad_Doms=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52951d6-8800-43cd-8182-a51288379a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AmpAmp\n",
    "\n",
    "LLHWidths(\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/AmpAmp.txt\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/llhs/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/widths/\",Bad_Doms=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cae531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PhsPhs\n",
    "\n",
    "LLHWidths(\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/PhsPhs.txt\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/llhs/\",\"/data/user/anegi/ppc/LLHs/spice_ftp-v2/widths/\",Bad_Doms=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5acdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4d721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99357bed-eb6f-4619-af54-5f778ead648f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IceCube (py3-v4.2.1)",
   "language": "python",
   "name": "py3-v4.2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
